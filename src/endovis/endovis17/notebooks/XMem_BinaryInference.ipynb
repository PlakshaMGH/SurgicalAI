{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58342a89-48bc-4ffe-896f-c9148629fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583132f0-df43-444b-8930-379bdb6805b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XMem_path = os.path.abspath('./XMem')\n",
    "sys.path.append(XMem_path)\n",
    "# !wget -P ./saves/ https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a30f0a10-f32f-4ecf-bfb9-10b01f7bd9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "from torchmetrics.classification import Dice\n",
    "\n",
    "# from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n",
    "# from inference.data.mask_mapper import MaskMapper\n",
    "from model.network import XMem\n",
    "from inference.inference_core import InferenceCore\n",
    "from inference.data.mask_mapper import MaskMapper\n",
    "\n",
    "from inference.interact.interactive_utils import image_to_torch, index_numpy_to_one_hot_torch, torch_prob_to_numpy_mask\n",
    "\n",
    "from progressbar import progressbar\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# default configuration\n",
    "config = {\n",
    "    'top_k': 30,\n",
    "    'mem_every': 5,\n",
    "    'deep_update_every': -1,\n",
    "    'enable_long_term': True,\n",
    "    'enable_long_term_count_usage': True,\n",
    "    'num_prototypes': 128,\n",
    "    'min_mid_term_frames': 5,\n",
    "    'max_mid_term_frames': 10,\n",
    "    'max_long_term_elements': 10000,\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Using GPU')\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  print('CUDA not available. Please connect to a GPU instance if possible.')\n",
    "  device = 'cpu'\n",
    "\n",
    "# network = XMem(config, '../XMem/saves/XMem.pth').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a73ca69-74b0-4bda-9be7-b86eec6b00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 16 23:46:28 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA L40                     On  | 00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              78W / 300W |   1556MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f754443a-ecea-4b31-ba0a-ad178f1dd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "COLOR = (3, 192, 60)\n",
    "\n",
    "# processor = InferenceCore(network, config=config)\n",
    "# NUM_OBJECTS = 1 # Binary Segmentation\n",
    "# processor.set_all_labels(range(1, NUM_OBJECTS+1))\n",
    "\n",
    "main_folder = Path(\"./data\")\n",
    "\n",
    "VIDEOS_PATH = main_folder/\"endo17_binary\"/\"frames\"\n",
    "MASKS_PATH = main_folder/\"endo17_binary\"/\"masks\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d0b039-36e8-4128-920e-824bc13c7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary2color(binary_mask, color):\n",
    "    binary_mask = torch_prob_to_numpy_mask(binary_mask)\n",
    "    pred_mask = np.tile(binary_mask[..., np.newaxis], (1,1,3)) # Make it 3 Channel\n",
    "    mask = np.where(pred_mask == (1,)*3, color, 0).astype('uint8') # Convert Prediction with Color\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db1b5d5-a31e-4dda-ab95-047d377c83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames2video(frames_dict, folder_save_path, video_name, FPS=5):\n",
    "    frame = frames_dict[list(frames_dict.keys())[-1]]\n",
    "    size1,size2,_ = frame.shape\n",
    "    out = cv2.VideoWriter(f'{folder_save_path}/{video_name}_{FPS}FPS.mp4', cv2.VideoWriter_fourcc(*'mp4v'), FPS, (size2, size1), True)\n",
    "    # Sorting the frames according to frame number eg: frame_007.png\n",
    "    for _,i in sorted(frames_dict.items(), key=lambda x: x[0]):\n",
    "        out_img = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "        out.write(out_img)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72887f87-526e-4644-bd80-e3b5db8d62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIoU(pred_frames, gt_path):\n",
    "    metric = BinaryJaccardIndex()\n",
    "    dice_metric = Dice()\n",
    "    \n",
    "    IoU = []\n",
    "    dice = []\n",
    "    \n",
    "    for frame_name, mask in pred_frames.items():\n",
    "        mask = torch_prob_to_numpy_mask(mask)\n",
    "        try:\n",
    "            truth_mask = io.imread(gt_path/frame_name)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        truth_mask = np.where(truth_mask == 255, 1, truth_mask)\n",
    "        if np.sum(truth_mask) == 0:\n",
    "            continue\n",
    "        truth_mask = torch.tensor(truth_mask)\n",
    "        IoU.append(metric(torch.tensor(mask), truth_mask).item())\n",
    "        dice.append(dice_metric(torch.tensor(mask), truth_mask).item())\n",
    "        \n",
    "    meanIoU = sum(IoU)/len(IoU)\n",
    "    meanDice = sum(dice)/len(dice)\n",
    "    \n",
    "    return meanIoU, IoU, meanDice, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ec5895-4780-4277-b42c-26f2f7f4740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_normalization = transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "\n",
    "def resize_mask(mask, size):\n",
    "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "        h, w = mask.shape[-2:]\n",
    "        min_hw = min(h, w)\n",
    "        return F.interpolate(mask, (int(h/min_hw*size), int(w/min_hw*size)), \n",
    "                    mode='nearest')[0]\n",
    "\n",
    "def singleVideoInference(images_paths, first_mask, processor, size = -1):\n",
    "    predictions = {}\n",
    "    frames = {}\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "\n",
    "        images_paths = sorted(images_paths)\n",
    "\n",
    "        # First Frame\n",
    "        frame = io.imread(images_paths[0])\n",
    "        shape = frame.shape[:2]\n",
    "        if size < 0:\n",
    "            im_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                im_normalization,\n",
    "            ])\n",
    "        else:\n",
    "            im_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                im_normalization,\n",
    "                transforms.Resize(size, interpolation=InterpolationMode.BILINEAR),\n",
    "            ])\n",
    "            \n",
    "        frame_torch = im_transform(frame).to(device)\n",
    "        first_mask = first_mask.astype(np.uint8)\n",
    "        if size > 0:\n",
    "            first_mask = torch.tensor(first_mask).to(device)\n",
    "            first_mask = resize_mask(first_mask, size)\n",
    "        else:\n",
    "            NUM_OBJECTS = 1 # Binary Segmentation\n",
    "            first_mask = index_numpy_to_one_hot_torch(first_mask, NUM_OBJECTS+1).to(device)\n",
    "            first_mask = first_mask[1:]\n",
    "            \n",
    "        prediction = processor.step(frame_torch, first_mask)\n",
    "        \n",
    "        for image_path in tqdm(images_paths[1:]):\n",
    "            frame = io.imread(image_path)\n",
    "            # convert numpy array to pytorch tensor format\n",
    "            frame_torch = im_transform(frame).to(device)\n",
    "            \n",
    "            prediction = processor.step(frame_torch)\n",
    "            # Upsample to original size if needed\n",
    "            if size > 0:\n",
    "                prediction = F.interpolate(prediction.unsqueeze(1), shape, mode='bilinear', align_corners=False)[:,0]\n",
    "            predictions[image_path.name] = prediction\n",
    "            frames[image_path.name] = frame\n",
    "\n",
    "    return frames, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add1feb9-c9a4-4082-9972-19ae9c521664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstMaskGT(image_files, mask_folder):\n",
    "    image_files = sorted(image_files)\n",
    "\n",
    "    for idx, image_path in enumerate(image_files):        \n",
    "        \n",
    "        # Getting the Path to Mask Ground Truth using RGB Image path\n",
    "        mask_path = mask_folder/image_path.parent.name/image_path.name\n",
    "        \n",
    "        mask = io.imread(mask_path)\n",
    "        # All 255 Values replaced with 1, other values remain as it is.\n",
    "        mask = np.where(mask == 255, 1, mask)\n",
    "        \n",
    "        if np.sum(mask) > 0:\n",
    "            return mask, idx\n",
    "            \n",
    "    return None, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4aac47-f043-40c4-a3cc-d53d6139a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doInference(network_path, config, frames_folder, mask_folder,\n",
    "                subset = None, pred_mask_folder = None, size = -1):\n",
    "    overallIoU = []\n",
    "    overallDice = []\n",
    "    for video_folder in sorted(frames_folder.iterdir()):\n",
    "\n",
    "        if subset is not None and video_folder.name not in subset:\n",
    "            continue\n",
    "    \n",
    "        # Clearing GPU Cache\n",
    "        torch.cuda.empty_cache()\n",
    "        network = XMem(config, network_path).eval().to(device)\n",
    "        processor = InferenceCore(network, config=config)\n",
    "        NUM_OBJECTS = 1 # Binary Segmentation\n",
    "        processor.set_all_labels(range(1, NUM_OBJECTS+1))\n",
    "        \n",
    "        # All Images\n",
    "        image_files = sorted(list(video_folder.iterdir()))\n",
    "        if pred_mask_folder:\n",
    "            mask_path = [i for i in pred_mask_folder.iterdir() if video_folder.name in i.name][0]\n",
    "            mask = io.imread(mask_path)\n",
    "            # All 0 pixel is 0, everything else(which is mask) is 1\n",
    "            mask = np.where(mask == 0, 0, 1)\n",
    "            # seq_01_0.png -> Two Splits, one on '_', other on '.'\n",
    "            start_idx = int((mask_path.name.split('_')[-1]).split('.')[0])\n",
    "        else: # Ground Truth\n",
    "            mask, start_idx = firstMaskGT(image_files, mask_folder)\n",
    "    \n",
    "        print(f\"Running Inference on {video_folder.name}...\")\n",
    "        frames, predictions = singleVideoInference(image_files[start_idx:], mask,\n",
    "                                                  processor, size = size)\n",
    "        IoU, _, dice, _ = getIoU(predictions, mask_folder/video_folder.name)\n",
    "        print(f\"Video \\\"{video_folder.name}\\\", mean IoU is: {IoU}\")\n",
    "        print(f\"Video \\\"{video_folder.name}\\\", mean dice is: {dice}\")\n",
    "        \n",
    "        overallIoU.append(IoU)\n",
    "        overallDice.append(dice)\n",
    "        print()\n",
    "\n",
    "        del network, processor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"Average IoU over all videos is: {sum(overallIoU)/len(overallIoU)}.\")\n",
    "    print(f\"Average Dice over all videos is: {sum(overallDice)/len(overallDice)}.\")\n",
    "\n",
    "    return overallIoU, overallDice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd5dd2-72b9-4825-8682-647c196be83e",
   "metadata": {},
   "source": [
    "## Check all .pth files and select best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337d6cc-7c64-4b56-a7b1-23f4d78628cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for network_path in Path(\"./saves/Nov15_20.28.13_EndoVis17_Binary\").iterdir():\n",
    "    if 'checkpoint' in network_path.name or '.pth' not in network_path.name:\n",
    "        continue\n",
    "    paths.append(network_path)\n",
    "\n",
    "IoUs = {}\n",
    "for network_path in sorted(paths, key = lambda x: int(x.name.split('_')[-1].split('.')[0])):\n",
    "    print(network_path.name)\n",
    "    test_subset = {i.name for i in VIDEOS_PATH.iterdir() if 'test' in i.name}\n",
    "    overallIoU, overallDice = doInference(network_path, config, VIDEOS_PATH, MASKS_PATH,\n",
    "                                          subset = test_subset, size = 384)\n",
    "    IoUs[network_path.name] = sum(overallIoU)/len(overallIoU)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e014088e-33f1-42fb-b2ef-da30c82e0a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed30a568-bd22-47de-af93-14ec004a7493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nov15_20.28.13_EndoVis17_Binary_1850.pth', 0.9230308244198298)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(IoUs.items(), key=lambda x: x[1], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6caf3cc8-6905-4c92-9a59-9032b143d4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_01_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_01_test\", mean IoU is: 0.8832564353942871\n",
      "Video \"instrument_dataset_01_test\", mean dice is: 0.9917536160430392\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_02_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:21<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_02_test\", mean IoU is: 0.8809122201558706\n",
      "Video \"instrument_dataset_02_test\", mean dice is: 0.9911449205231022\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_03_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:22<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_03_test\", mean IoU is: 0.9524074527057441\n",
      "Video \"instrument_dataset_03_test\", mean dice is: 0.9929651432746166\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_04_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:24<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_04_test\", mean IoU is: 0.9484399033559335\n",
      "Video \"instrument_dataset_04_test\", mean dice is: 0.9902801425070376\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_05_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:21<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_05_test\", mean IoU is: 0.9179814574686257\n",
      "Video \"instrument_dataset_05_test\", mean dice is: 0.9921518354802519\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_06_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_06_test\", mean IoU is: 0.9220134760882404\n",
      "Video \"instrument_dataset_06_test\", mean dice is: 0.9865542835480458\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_07_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_07_test\", mean IoU is: 0.929388814278551\n",
      "Video \"instrument_dataset_07_test\", mean dice is: 0.9836911430230012\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_08_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_08_test\", mean IoU is: 0.9555812856635532\n",
      "Video \"instrument_dataset_08_test\", mean dice is: 0.9922536684049142\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_09_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [01:37<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_09_test\", mean IoU is: 0.909089560692127\n",
      "Video \"instrument_dataset_09_test\", mean dice is: 0.9907494801342687\n",
      "\n",
      "Hyperparameters read from the model weights: C^k=64, C^v=512, C^h=64\n",
      "Single object mode: False\n",
      "Running Inference on instrument_dataset_10_test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299/299 [01:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video \"instrument_dataset_10_test\", mean IoU is: 0.9312376383953669\n",
      "Video \"instrument_dataset_10_test\", mean dice is: 0.9918697667759796\n",
      "\n",
      "Average IoU over all videos is: 0.9230308244198298.\n",
      "Average Dice over all videos is: 0.9903413999714257.\n"
     ]
    }
   ],
   "source": [
    "network_path = \"./saves/Nov15_20.28.13_EndoVis17_Binary/XMem_Binary_Endo17.pth\"\n",
    "test_subset = {i.name for i in VIDEOS_PATH.iterdir() if 'test' in i.name}\n",
    "overallIoU, overallDice = doInference(network_path, config, VIDEOS_PATH, MASKS_PATH,\n",
    "                                          subset = test_subset, size = 384)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58342a89-48bc-4ffe-896f-c9148629fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583132f0-df43-444b-8930-379bdb6805b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "XMem_path = os.path.abspath('./XMem')\n",
    "sys.path.append(XMem_path)\n",
    "# !wget -P ./saves/ https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f0a10-f32f-4ecf-bfb9-10b01f7bd9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from inspect import getsource\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import re\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "# from torchmetrics.classification import BinaryJaccardIndex\n",
    "# from torchmetrics.classification import Dice\n",
    "from torchmetrics.functional.classification import binary_jaccard_index\n",
    "from torchmetrics.functional import dice\n",
    "\n",
    "# from inference.data.test_datasets import LongTestDataset, DAVISTestDataset, YouTubeVOSTestDataset\n",
    "# from inference.data.mask_mapper import MaskMapper\n",
    "from model.network import XMem\n",
    "from inference.inference_core import InferenceCore\n",
    "from inference.data.mask_mapper import MaskMapper\n",
    "\n",
    "from inference.interact.interactive_utils import image_to_torch, index_numpy_to_one_hot_torch, torch_prob_to_numpy_mask\n",
    "\n",
    "from progressbar import progressbar\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# default configuration\n",
    "config = {\n",
    "    'top_k': 30,\n",
    "    'mem_every': 5,\n",
    "    'deep_update_every': -1,\n",
    "    'enable_long_term': True,\n",
    "    'enable_long_term_count_usage': True,\n",
    "    'num_prototypes': 128,\n",
    "    'min_mid_term_frames': 5,\n",
    "    'max_mid_term_frames': 10,\n",
    "    'max_long_term_elements': 10000,\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Using GPU')\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  print('CUDA not available. Please connect to a GPU instance if possible.')\n",
    "  device = 'cpu'\n",
    "\n",
    "# network = XMem(config, '../XMem/saves/XMem.pth').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73ca69-74b0-4bda-9be7-b86eec6b00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be6ca1-a27e-4750-a54f-ea70c862b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# COLOR = (3, 192, 60)\n",
    "\n",
    "\n",
    "# # Pulmonary Vein\n",
    "# main_folder = Path(\"./data\")\n",
    "# VIDEOS_PATH = main_folder/\"tframes\"\n",
    "# MASKS_PATH = main_folder/\"tmasks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754443a-ecea-4b31-ba0a-ad178f1dd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "COLOR = (3, 192, 60)\n",
    "\n",
    "# processor = InferenceCore(network, config=config)\n",
    "# NUM_OBJECTS = 1 # Binary Segmentation\n",
    "# processor.set_all_labels(range(1, NUM_OBJECTS+1))\n",
    "\n",
    "main_folder = Path(\"./data\")\n",
    "VIDEOS_PATH = main_folder/\"frames\"\n",
    "MASKS_PATH = main_folder/\"masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0b039-36e8-4128-920e-824bc13c7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depreciated\n",
    "def binary2color(binary_mask, color):\n",
    "    binary_mask = torch_prob_to_numpy_mask(binary_mask)\n",
    "    pred_mask = np.tile(binary_mask[..., np.newaxis], (1,1,3)) # Make it 3 Channel\n",
    "    mask = np.where(pred_mask == (1,)*3, color, 0).astype('uint8') # Convert Prediction with Color\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_map(pred_mask: np.ndarray, gt_mask: np.ndarray):\n",
    "    # Intersection of pred_mask and gt_mask: True Positive\n",
    "    true_positive = np.bitwise_and(pred_mask, gt_mask)\n",
    "    # Only Pred not GT: False Positive\n",
    "    false_positive = np.bitwise_and(pred_mask, np.bitwise_not(gt_mask))\n",
    "    # Only GT not Pred: False Negative\n",
    "    false_negative = np.bitwise_and(np.bitwise_not(pred_mask), gt_mask)\n",
    "\n",
    "    # Colors\n",
    "    green = (0, 255, 0)\n",
    "    red = (255, 0, 0)\n",
    "    blue = (0, 0, 255)\n",
    "\n",
    "    # Creating Color Map Image\n",
    "    h,w = pred_mask.shape[:2]\n",
    "    color_map = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    color_map[true_positive!=0] = green\n",
    "    color_map[false_positive!=0] = red\n",
    "    color_map[false_negative!=0] = blue\n",
    "\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f098b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Mask\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATQElEQVR4nO3df6iW9f348dfxmLcax9MyjigeTWGgaaGeIyO11igcZZEw2gprURtMdvyVEOpsG7npwf0QIadxZIibaP6xhQ5qTRpqziQ7asU2lC3IQ05cI86xglPq/f3j89n5fs4s562+vO/79HjA9ce5uC6vF5dwnrzv6z73XVMsFosBAFdYv3IPAEDfJDAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQov/VvuC5c+fixIkTUVdXFzU1NVf78gBchmKxGKdPn44RI0ZEv34XXqNc9cCcOHEiGhsbr/ZlAbiCOjo6YuTIkRc85qoHpq6uLiIiZsQ90T+uudqXB+AynIlPYl+80PO7/EKuemD+/bJY/7gm+tcIDEBV+d9Pr7yYRxwe8gOQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkuKTArF+/PsaMGRMDBw6MpqameOWVV670XABUuZIDs3379li0aFEsX748Dh8+HLfddlvcfffdcfz48Yz5AKhSJQdmzZo18a1vfSu+/e1vx/jx42Pt2rXR2NgYGzZsyJgPgCpVUmA+/vjjaG9vj5kzZ/baP3PmzNi/f/+nntPd3R1dXV29NgD6vpIC895778XZs2dj2LBhvfYPGzYsTp48+anntLa2Rn19fc/m2ywBPh8u6SH/f37RTLFY/Mwvn1m2bFl0dnb2bB0dHZdySQCqTEnfaHnDDTdEbW3teauVU6dOnbeq+bdCoRCFQuHSJwSgKpW0ghkwYEA0NTXFrl27eu3ftWtXTJs27YoOBkB1K2kFExGxePHieOSRR6K5uTluvfXWaGtri+PHj8fcuXMz5gOgSpUcmG984xvxr3/9K1asWBH/+Mc/YuLEifHCCy/E6NGjM+YDoErVFIvF4tW8YFdXV9TX18cdcX/0r7nmal4agMt0pvhJ7I4d0dnZGUOGDLngsT6LDIAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSlBSY1tbWmDp1atTV1UVDQ0PMnj07jh49mjUbAFWspMDs2bMnWlpa4sCBA7Fr1644c+ZMzJw5Mz788MOs+QCoUv1LOfj3v/99r583bdoUDQ0N0d7eHrfffvsVHQyA6lZSYP5TZ2dnRERcf/31n3lMd3d3dHd39/zc1dV1OZcEoEpc8kP+YrEYixcvjhkzZsTEiRM/87jW1taor6/v2RobGy/1kgBUkUsOzLx58+LNN9+Mbdu2XfC4ZcuWRWdnZ8/W0dFxqZcEoIpc0ktk8+fPj507d8bevXtj5MiRFzy2UChEoVC4pOEAqF4lBaZYLMb8+fPj+eefj927d8eYMWOy5gKgypUUmJaWlti6dWvs2LEj6urq4uTJkxERUV9fH4MGDUoZEIDqVNIzmA0bNkRnZ2fccccdMXz48J5t+/btWfMBUKVKfokMAC6GzyIDIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNAiv7lHgAu10snjpR7BPqQr46YVO4R+gwrGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJDisgLT2toaNTU1sWjRois0DgB9xSUH5uDBg9HW1ha33HLLlZwHgD7ikgLzwQcfxJw5c2Ljxo3xhS984UrPBEAfcEmBaWlpiVmzZsVdd931X4/t7u6Orq6uXhsAfV/JX5n83HPPxaFDh+LgwYMXdXxra2s8/fTTJQ8GQHUraQXT0dERCxcujC1btsTAgQMv6pxly5ZFZ2dnz9bR0XFJgwJQXUpawbS3t8epU6eiqampZ9/Zs2dj7969sW7duuju7o7a2tpe5xQKhSgUCldmWgCqRkmBufPOO+Ott97qte+xxx6LcePGxZIlS86LCwCfXyUFpq6uLiZOnNhr37XXXhtDhw49bz8An2/+kh+AFCW/i+w/7d69+wqMAUBfYwUDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMAClKDsy7774bDz/8cAwdOjQGDx4ckyZNivb29ozZAKhi/Us5+P3334/p06fHV77ylXjxxRejoaEh/v73v8d1112XNB4A1aqkwKxevToaGxtj06ZNPftuvPHGKz0TAH1ASS+R7dy5M5qbm+OBBx6IhoaGmDx5cmzcuPGC53R3d0dXV1evDYC+r6TAvP3227Fhw4b44he/GC+99FLMnTs3FixYEL/61a8+85zW1taor6/v2RobGy97aAAqX02xWCxe7MEDBgyI5ubm2L9/f8++BQsWxMGDB+PVV1/91HO6u7uju7u75+eurq5obGyMO+L+6F9zzWWMDv/jpRNHyj0CfchXR0wq9wgV7Uzxk9gdO6KzszOGDBlywWNLWsEMHz48brrppl77xo8fH8ePH//McwqFQgwZMqTXBkDfV1Jgpk+fHkePHu2179ixYzF69OgrOhQA1a+kwDzxxBNx4MCBWLVqVfztb3+LrVu3RltbW7S0tGTNB0CVKikwU6dOjeeffz62bdsWEydOjB/96Eexdu3amDNnTtZ8AFSpkv4OJiLi3nvvjXvvvTdjFgD6EJ9FBkAKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBT9yz0AXK6vjphU7hGAT2EFA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFKUFJgzZ87EU089FWPGjIlBgwbF2LFjY8WKFXHu3Lms+QCoUiV9H8zq1avj2Wefjc2bN8eECRPi9ddfj8ceeyzq6+tj4cKFWTMCUIVKCsyrr74a999/f8yaNSsiIm688cbYtm1bvP766ynDAVC9SnqJbMaMGfHyyy/HsWPHIiLijTfeiH379sU999zzmed0d3dHV1dXrw2Avq+kFcySJUuis7Mzxo0bF7W1tXH27NlYuXJlPPTQQ595Tmtrazz99NOXPSgA1aWkFcz27dtjy5YtsXXr1jh06FBs3rw5fvazn8XmzZs/85xly5ZFZ2dnz9bR0XHZQwNQ+UpawTz55JOxdOnSePDBByMi4uabb4533nknWltb49FHH/3UcwqFQhQKhcufFICqUtIK5qOPPop+/XqfUltb623KAJynpBXMfffdFytXroxRo0bFhAkT4vDhw7FmzZp4/PHHs+YDoEqVFJhnnnkmvv/978d3v/vdOHXqVIwYMSK+853vxA9+8IOs+QCoUjXFYrF4NS/Y1dUV9fX1cUfcH/1rrrmalwbgMp0pfhK7Y0d0dnbGkCFDLniszyIDIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAU/a/2BYvFYkREnIlPIopX++oAXI4z8UlE/P/f5Rdy1QNz+vTpiIjYFy9c7UsDcIWcPn066uvrL3hMTfFiMnQFnTt3Lk6cOBF1dXVRU1Nzyf9OV1dXNDY2RkdHRwwZMuQKTti3uE8Xx326OO7TxenL96lYLMbp06djxIgR0a/fhZ+yXPUVTL9+/WLkyJFX7N8bMmRIn/sPzOA+XRz36eK4Txenr96n/7Zy+TcP+QFIITAApKjawBQKhfjhD38YhUKh3KNUNPfp4rhPF8d9ujju0/+46g/5Afh8qNoVDACVTWAASCEwAKQQGABSVG1g1q9fH2PGjImBAwdGU1NTvPLKK+UeqaK0trbG1KlTo66uLhoaGmL27Nlx9OjRco9V0VpbW6OmpiYWLVpU7lEqzrvvvhsPP/xwDB06NAYPHhyTJk2K9vb2co9VUc6cORNPPfVUjBkzJgYNGhRjx46NFStWxLlz58o9WtlUZWC2b98eixYtiuXLl8fhw4fjtttui7vvvjuOHz9e7tEqxp49e6KlpSUOHDgQu3btijNnzsTMmTPjww8/LPdoFengwYPR1tYWt9xyS7lHqTjvv/9+TJ8+Pa655pp48cUX4y9/+Uv8/Oc/j+uuu67co1WU1atXx7PPPhvr1q2Lv/71r/GTn/wkfvrTn8YzzzxT7tHKpirfpvylL30ppkyZEhs2bOjZN378+Jg9e3a0traWcbLK9c9//jMaGhpiz549cfvtt5d7nIrywQcfxJQpU2L9+vXx4x//OCZNmhRr164t91gVY+nSpfGnP/3JqwT/xb333hvDhg2LX/7ylz37vva1r8XgwYPj17/+dRknK5+qW8F8/PHH0d7eHjNnzuy1f+bMmbF///4yTVX5Ojs7IyLi+uuvL/MklaelpSVmzZoVd911V7lHqUg7d+6M5ubmeOCBB6KhoSEmT54cGzduLPdYFWfGjBnx8ssvx7FjxyIi4o033oh9+/bFPffcU+bJyueqf9jl5Xrvvffi7NmzMWzYsF77hw0bFidPnizTVJWtWCzG4sWLY8aMGTFx4sRyj1NRnnvuuTh06FAcPHiw3KNUrLfffjs2bNgQixcvju9973vx2muvxYIFC6JQKMQ3v/nNco9XMZYsWRKdnZ0xbty4qK2tjbNnz8bKlSvjoYceKvdoZVN1gfm3//yo/2KxeFkf/9+XzZs3L958883Yt29fuUepKB0dHbFw4cL4wx/+EAMHDiz3OBXr3Llz0dzcHKtWrYqIiMmTJ8ef//zn2LBhg8D8H9u3b48tW7bE1q1bY8KECXHkyJFYtGhRjBgxIh599NFyj1cWVReYG264IWpra89brZw6deq8VQ0R8+fPj507d8bevXuv6Nck9AXt7e1x6tSpaGpq6tl39uzZ2Lt3b6xbty66u7ujtra2jBNWhuHDh8dNN93Ua9/48ePjN7/5TZkmqkxPPvlkLF26NB588MGIiLj55pvjnXfeidbW1s9tYKruGcyAAQOiqakpdu3a1Wv/rl27Ytq0aWWaqvIUi8WYN29e/Pa3v40//vGPMWbMmHKPVHHuvPPOeOutt+LIkSM9W3Nzc8yZMyeOHDkiLv9r+vTp573F/dixYzF69OgyTVSZPvroo/O+gKu2tvZz/TblqlvBREQsXrw4HnnkkWhubo5bb7012tra4vjx4zF37txyj1YxWlpaYuvWrbFjx46oq6vrWfHV19fHoEGDyjxdZairqzvvmdS1114bQ4cO9azq/3jiiSdi2rRpsWrVqvj6178er732WrS1tUVbW1u5R6so9913X6xcuTJGjRoVEyZMiMOHD8eaNWvi8ccfL/do5VOsUr/4xS+Ko0ePLg4YMKA4ZcqU4p49e8o9UkWJiE/dNm3aVO7RKtqXv/zl4sKFC8s9RsX53e9+V5w4cWKxUCgUx40bV2xrayv3SBWnq6uruHDhwuKoUaOKAwcOLI4dO7a4fPnyYnd3d7lHK5uq/DsYACpf1T2DAaA6CAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNAiv8Hdjk8IibbYe8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Mask\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Map\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.zeros((10,10), dtype=np.uint8)\n",
    "a[4:8, 4:8] = 1\n",
    "b = np.zeros((10,10), dtype=np.uint8)\n",
    "b[2:6, 2:6] = 1\n",
    "c = color_map(a, b)\n",
    "print(\"Predicted Mask\")\n",
    "plt.imshow(a); plt.show()\n",
    "print(\"Ground Truth Mask\")\n",
    "plt.imshow(b); plt.show()\n",
    "print(\"Color Map\")\n",
    "plt.imshow(c); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1b5d5-a31e-4dda-ab95-047d377c83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames2video(frames_dict, folder_save_path, video_name, FPS=5):\n",
    "    video_path = f'{folder_save_path}/{video_name}_{FPS}FPS.mp4'\n",
    "    print(\"Creating video and saving:\", video_path)\n",
    "    frame = frames_dict[list(frames_dict.keys())[-1]]\n",
    "    size1,size2,_ = frame.shape\n",
    "    out = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), FPS, (size2, size1), True)\n",
    "    # Sorting the frames according to frame number eg: frame_007.png\n",
    "    for _,i in sorted(frames_dict.items(), key=lambda x: x[0]):\n",
    "        out_img = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "        out.write(out_img)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d97b3-45cd-4bd3-b3a9-93d4c20ae362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depreciated: Implemented inside getIoU function\n",
    "def pred2overlay(og_frames, pred_frames):\n",
    "    overlay_dict = {}\n",
    "    for frame_name, frame in og_frames.items():\n",
    "        colored_mask = binary2color(pred_frames[frame_name], (34,139,34)) # forestgreen https://www.rapidtables.com/web/color/green-color.html\n",
    "        overlay = cv2.addWeighted(frame, 1, colored_mask, 0.5, 0)\n",
    "        overlay_dict[frame_name] = overlay\n",
    "    return overlay_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a0661-5ef8-46b1-b7f8-0d23b38f64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIoU(pred_frames, path_dicts, video=True, og_frames = None, save_path=None):\n",
    "    \n",
    "    IoU = [0]*len(pred_frames)\n",
    "    dice_ = [0]*len(pred_frames)\n",
    "    overlaid_images = {}\n",
    "    # get the first mask frame from pred_frames dictionary and get its shape\n",
    "    _,h,w = pred_frames[list(pred_frames.keys())[0]].shape # [0]:first key\n",
    "    for i, (frame_name, mask) in enumerate(tqdm(pred_frames.items())):\n",
    "        np_mask = torch_prob_to_numpy_mask(mask) # predictions probabilities to numpy mask\n",
    "        torch_mask = torch.tensor(np_mask).to(device)\n",
    "        \n",
    "        truth_mask = io.imread(path_dicts[frame_name][1]) # 0: frame_path, 1: mask_path\n",
    "        truth_mask[truth_mask == 255] = 1\n",
    "        if np.sum(truth_mask) < (0.01*h*w): # if mask is empty or covers less than 1% of image\n",
    "            continue\n",
    "\n",
    "        if video:\n",
    "            overlaid_images[frame_name] = cv2.addWeighted(og_frames[frame_name], 1, color_map(np_mask, truth_mask), 0.5, 0)\n",
    "        if save_path:\n",
    "            io.imsave(save_path/frame_name, np_mask, check_contrast=False)\n",
    "\n",
    "        truth_mask = torch.tensor(truth_mask).to(device)\n",
    "        IoU[i] = binary_jaccard_index(torch_mask, truth_mask)\n",
    "        dice_[i] = dice(torch_mask, truth_mask)\n",
    "        \n",
    "    meanIoU = sum(IoU)/len(IoU)\n",
    "    meanDice = sum(dice_)/len(dice_)\n",
    "    \n",
    "    return meanIoU, IoU, meanDice, dice, overlaid_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec5895-4780-4277-b42c-26f2f7f4740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_normalization = transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "\n",
    "def resize_mask(mask, size):\n",
    "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
    "        h, w = mask.shape[-2:]\n",
    "        min_hw = min(h, w)\n",
    "        return F.interpolate(mask, (int(h/min_hw*size), int(w/min_hw*size)), \n",
    "                    mode='nearest')[0]\n",
    "\n",
    "def singleVideoInference(images_paths, first_mask, processor, size = -1):\n",
    "    predictions = {}\n",
    "    frames = {}\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "\n",
    "        # images_paths = sorted(images_paths)\n",
    "\n",
    "        # First Frame\n",
    "        frame = io.imread(images_paths[0])\n",
    "        og_shape = frame.shape[:2]\n",
    "        if size < 0:\n",
    "            im_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                im_normalization,\n",
    "            ])\n",
    "        else:\n",
    "            im_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                im_normalization,\n",
    "                transforms.Resize(size, interpolation=InterpolationMode.BILINEAR, antialias=False),\n",
    "            ])\n",
    "            \n",
    "        frame_torch = im_transform(frame).to(device)\n",
    "        first_mask = first_mask.astype(np.uint8)\n",
    "        if size > 0:\n",
    "            first_mask = torch.tensor(first_mask).to(device)\n",
    "            first_mask = resize_mask(first_mask, size)\n",
    "        else:\n",
    "            NUM_OBJECTS = 1 # Binary Segmentation\n",
    "            first_mask = index_numpy_to_one_hot_torch(first_mask, NUM_OBJECTS+1).to(device)\n",
    "            first_mask = first_mask[1:]\n",
    "            \n",
    "        prediction = processor.step(frame_torch, first_mask)\n",
    "        \n",
    "        for image_path in tqdm(images_paths[1:]):\n",
    "            frame = io.imread(image_path)\n",
    "            # convert numpy array to pytorch tensor format\n",
    "            frame_torch = im_transform(frame).to(device)\n",
    "            \n",
    "            prediction = processor.step(frame_torch)\n",
    "            # Upsample to original size if needed\n",
    "            if size > 0:\n",
    "                prediction = F.interpolate(prediction.unsqueeze(1), og_shape, mode='bilinear', align_corners=False)[:,0]\n",
    "            predictions[image_path.name] = prediction\n",
    "            frames[image_path.name] = frame\n",
    "\n",
    "    return frames, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1feb9-c9a4-4082-9972-19ae9c521664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstMaskGT(mask_files):\n",
    "\n",
    "    for idx, mask_path in enumerate(mask_files):        \n",
    "        \n",
    "        mask = io.imread(mask_path)\n",
    "        # All 255 Values replaced with 1, other values remain as it is.\n",
    "        mask = np.where(mask == 255, 1, mask)\n",
    "        h,w = mask.shape\n",
    "        if np.sum(mask) > 0 and ( np.sum(mask) > (0.01*h*w) ): # or can use percentage of image, like > 1%\n",
    "            return mask, idx\n",
    "            \n",
    "    return None, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4aac47-f043-40c4-a3cc-d53d6139a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doInference(network_path, config, sorted_paths, size = -1, video=False):\n",
    "    overallIoU = []\n",
    "    overallDice = []\n",
    "    for pat_name, sorted_paths_dict in sorted_paths.items():\n",
    "    \n",
    "        # Clearing GPU Cache\n",
    "        torch.cuda.empty_cache()\n",
    "        network = XMem(config, network_path).eval().to(device)\n",
    "        processor = InferenceCore(network, config=config)\n",
    "        NUM_OBJECTS = 1 # Binary Segmentation\n",
    "        processor.set_all_labels(range(1, NUM_OBJECTS+1))\n",
    "\n",
    "        image_files = [img_path for img_path, _ in sorted_paths_dict.values()]\n",
    "        mask_files = [mask_path for _, mask_path in sorted_paths_dict.values()]\n",
    "        \n",
    "        # Getting first Ground Truth mask.\n",
    "        mask, start_idx = firstMaskGT(mask_files)\n",
    "        print(\"Mask starting from:\", start_idx)\n",
    "    \n",
    "        print(f\"Running Inference on {pat_name}...\")\n",
    "        frames, predictions = singleVideoInference(image_files[start_idx:], mask,\n",
    "                                                  processor, size = size)\n",
    "        save_path = None\n",
    "        if video:\n",
    "            save_path = Path(f\"./pred_masks/{pat_name}\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            \n",
    "        IoU, _, dice, _, overlaid_images = getIoU(predictions, sorted_paths_dict,\n",
    "                                 video=video, og_frames = frames, save_path=save_path)\n",
    "        \n",
    "        print(f\"Video \\\"{pat_name}\\\", mean IoU is: {IoU}\")\n",
    "        print(f\"Video \\\"{pat_name}\\\", mean dice is: {dice}\")\n",
    "\n",
    "        # Convert to Video\n",
    "        if video:\n",
    "            os.makedirs(\"./videos\", exist_ok=True)\n",
    "            frames2video(frames_dict=overlaid_images, folder_save_path = \"./videos\", video_name=pat_name, FPS=5)\n",
    "        \n",
    "        overallIoU.append(IoU)\n",
    "        overallDice.append(dice)\n",
    "        print()\n",
    "\n",
    "        del network, processor\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    print(f\"Average IoU over all videos is: {sum(overallIoU)/len(overallIoU)}.\")\n",
    "    print(f\"Average Dice over all videos is: {sum(overallDice)/len(overallDice)}.\")\n",
    "\n",
    "    return overallIoU, overallDice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd5dd2-72b9-4825-8682-647c196be83e",
   "metadata": {},
   "source": [
    "## Check all .pth files and select best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614489e-50fd-44bc-b469-8a84db5f01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_folder = \"Dec28_16.48.56_Binary_RLL_PA\" # Weights Folder\n",
    "patient1 = \"p14\" # Test Patient 1\n",
    "patient2 = \"p20\" # Test Patient 2\n",
    "comb = patient1+patient2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ae630-9d2a-40e7-b1a3-2e39239f97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATIENTS = set([patient1, patient2])\n",
    "# TEST_PATIENTS = set([\"rll-p01\", \"p01\", \"p02\", \"p03\"]) # For RLL PV and LUL PA dataset testing\n",
    "\n",
    "paths = {pat: {} for pat in TEST_PATIENTS}\n",
    "for folder in MASKS_PATH.iterdir():\n",
    "    pat_name = folder.name.split('_')[0]\n",
    "    if pat_name not in TEST_PATIENTS:\n",
    "        continue\n",
    "    for mask_path in folder.iterdir():\n",
    "        paths[pat_name][mask_path.name] = (VIDEOS_PATH/folder.name/mask_path.name, mask_path)\n",
    "\n",
    "sorted_paths = {pat: {k:v for k,v in sorted(l.items(), key=lambda x: x[0])} for pat, l in paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b1671d",
   "metadata": {},
   "source": [
    "### Inference using each `.pth` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337d6cc-7c64-4b56-a7b1-23f4d78628cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "for network_path in Path(f\"./saves/{saved_folder}\").iterdir():\n",
    "    if 'checkpoint' in network_path.name or '.pth' not in network_path.name:\n",
    "        continue\n",
    "    paths.append(network_path)\n",
    "        \n",
    "IoUs = {}\n",
    "for network_path in sorted(paths, key = lambda x: int(x.name.split('_')[-1].split('.')[0])):\n",
    "    print(network_path.name)\n",
    "    overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384)\n",
    "    IoUs[network_path.name] = sum(overallIoU)/len(overallIoU)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f4e9f-47a1-46a8-b34b-0ace508405de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in Decreasing Order the IoU\n",
    "sorted_path_iou = sorted(IoUs.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_path_iou[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ecee0-ee49-4268-8f45-a3ab3159936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All .pth files Inference Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb051b-6baa-4dd2-85ad-b448f8aad9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy2\n",
    "# Rename and Copy the best model to `saves`\n",
    "copy2(f\"./saves/{saved_folder}/{sorted_path_iou[0][0]}\", f\"./saves/XMem_BinaryRLLPA_All-{comb}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d609d-e86a-4b0d-85af-68ebec89928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename and Copy the Tensorboard Logs to `saves`\n",
    "for tensorboard_path in Path(f\"./saves/{saved_folder}\").iterdir():\n",
    "    if \"events.out\" not in tensorboard_path.name:\n",
    "        continue\n",
    "    copy2(tensorboard_path, f\"./saves/events.out.tfevents.All-{comb}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1fe88-d4a4-4aa0-9f22-75d34bccdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp ./saves/XMem_BinaryRLLPA_All-p14p20.pth s3://all-patients/weights/XMem/\n",
    "!aws s3 cp ./saves/events.out.tfevents.All-p14p20 s3://all-patients/logs/XMem/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa7bfc-9ef4-41f9-ae8e-1996ee951a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_path = f\"./saves/XMem_BinaryRLLPA_All-{comb}.pth\"\n",
    "os.makedirs(\"./pred_masks\", exist_ok=True)\n",
    "overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384, video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d6ab3-1330-43db-ba3e-91c9575c5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best .pth file Inference Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed68f27",
   "metadata": {},
   "source": [
    "### Loop thorugh all best `.pth` from each run and do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0908918-8f95-46d9-a95b-484f4c90aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for network_path in Path(f\"./saves\").iterdir():\n",
    "    if 'checkpoint' in network_path.name or '.pth' not in network_path.name:\n",
    "        continue\n",
    "    paths.append(network_path)\n",
    "os.makedirs(\"./pred_masks\", exist_ok=True)\n",
    "\n",
    "IoUs = {}\n",
    "for network_path in sorted(paths):\n",
    "    print(network_path.name)\n",
    "    # Get testing patients from the file name eg:XMem_BinaryRLLPA_All-p1p2 -> p1, p2\n",
    "    pat_comb = network_path.name.split(\"-\")[-1]\n",
    "    p1, p2 = [match.group() for match in re.finditer(r'p(\\d{1,2})', pat_comb)]\n",
    "    print(\"Test Patients:\", p1, p2)\n",
    "    TEST_PATIENTS = set([p1, p2])\n",
    "    paths = {pat: {} for pat in TEST_PATIENTS}\n",
    "\n",
    "    for folder in MASKS_PATH.iterdir():\n",
    "        pat_name = folder.name.split('_')[0]\n",
    "        if pat_name not in TEST_PATIENTS:\n",
    "            continue\n",
    "        for mask_path in folder.iterdir():\n",
    "            paths[pat_name][mask_path.name] = (VIDEOS_PATH/folder.name/mask_path.name, mask_path)\n",
    "\n",
    "    sorted_paths = {pat: {k:v for k,v in sorted(l.items(), key=lambda x: x[0])} for pat, l in paths.items()}\n",
    "\n",
    "    overallIoU, overallDice = doInference(network_path, config, sorted_paths, size = 384, video=True)\n",
    "    IoUs[network_path.name] = sum(overallIoU)/len(overallIoU)\n",
    "    print('*'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

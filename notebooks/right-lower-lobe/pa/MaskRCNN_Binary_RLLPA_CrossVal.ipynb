{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9cfd77-4c61-4354-972c-8ffc4e2e74df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117 True\n",
      "3.0.0\n",
      "11.7\n",
      "GCC 9.3\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594bd7a-5061-403f-8981-8b83ece41cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.13.1+cu117 cuda: True\n",
      "mmdetection: 3.0.0\n",
      "mmcv: 2.0.0\n",
      "mmengine: 0.7.3\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(\"torch version:\",torch.__version__, \"cuda:\",torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(\"mmdetection:\",mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "import mmcv\n",
    "print(\"mmcv:\",mmcv.__version__)\n",
    "\n",
    "# Check mmengine installation\n",
    "import mmengine\n",
    "print(\"mmengine:\",mmengine.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fd71a0-e707-4c72-9250-7a4367218c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmengine\n",
    "import mmdet\n",
    "\n",
    "from mmcv.transforms import Compose\n",
    "\n",
    "from mmengine import Config\n",
    "from mmengine.hooks import Hook\n",
    "from mmengine.runner import set_random_seed\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.utils import track_iter_progress\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "from mmdet.registry import VISUALIZERS, HOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2f3b72-658d-4750-adf2-bd637af20ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.color import label2rgb\n",
    "from skimage import io\n",
    "\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83aa797e-5123-42de-9787-fb86c0fe5d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config file from Pre-Trained model\n",
    "# https://github.com/open-mmlab/mmdetection/tree/master/configs/mask_rcnn\n",
    "config = \"./mmdetection/configs/mask_rcnn/mask-rcnn_r50_fpn_ms-poly-3x_coco.py\"\n",
    "\n",
    "cfg = Config.fromfile(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b1315b-a8df-4d02-b09b-d02ba454e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "processing mask-rcnn_r50_fpn_mstrain-poly_3x_coco...\n",
      "\u001b[32mmask_rcnn_r50_fpn_mstrain-poly_3x_coco_20210524_201154-21b550bb.pth exists in /home/ubuntu/pre_trained_checkpoints\u001b[0m\n",
      "\u001b[32mSuccessfully dumped mask-rcnn_r50_fpn_mstrain-poly_3x_coco.py to /home/ubuntu/pre_trained_checkpoints\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mim download mmdet --config mask-rcnn_r50_fpn_mstrain-poly_3x_coco --dest ./pre_trained_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfe5e78-439d-4bc5-a4cb-232072ae9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify dataset classes and color\n",
    "# https://github.com/open-mmlab/mmdetection/issues/9610#issuecomment-1383553783\n",
    "# Change the Keys to all lower case\n",
    "cfg.metainfo = {\n",
    "    'classes': ('Artery', ),\n",
    "    'palette': [\n",
    "        (220, 20, 60),\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "albu_train_transforms = [\n",
    "    dict(\n",
    "        type='ShiftScaleRotate',\n",
    "        shift_limit=0.3,\n",
    "        scale_limit=0.2,\n",
    "        rotate_limit=30,\n",
    "        interpolation=1,\n",
    "        p=0.4),\n",
    "    dict(\n",
    "        type='OneOf',\n",
    "        transforms=[\n",
    "            dict(\n",
    "                type='CLAHE',\n",
    "                clip_limit=5.0,\n",
    "                tile_grid_size=(11,11),\n",
    "                p=1.0),\n",
    "            dict(type='ColorJitter', brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2,p=1.0),\n",
    "            dict(type='RandomBrightnessContrast', brightness_limit=0.4, contrast_limit=0.4, p=1.0),\n",
    "            dict(type='Equalize', p=1.0),\n",
    "        ],\n",
    "        p=0.2),\n",
    "    dict(type='JpegCompression', quality_lower=65, quality_upper=95, p=0.1),\n",
    "    dict(\n",
    "        type='OneOf',\n",
    "        transforms=[\n",
    "            dict(type='Blur', blur_limit=3, p=1.0),\n",
    "            dict(type='MedianBlur', blur_limit=5, p=1.0),\n",
    "        ],\n",
    "        p=0.2),\n",
    "    dict(\n",
    "        type='OneOf',\n",
    "        transforms=[\n",
    "            dict(type='ElasticTransform', p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "            dict(type='GridDistortion', p=1),\n",
    "            dict(type='OpticalDistortion', distort_limit=2, shift_limit=0.5, p=1)\n",
    "        ],\n",
    "        p=0.2),\n",
    "    dict(\n",
    "        type='OneOf',\n",
    "        transforms=[\n",
    "            dict(type='CenterCrop', height = 448, width = 448, p=1),\n",
    "            dict(type='CropNonEmptyMaskIfExists', height = 720, width = 720, p=1),\n",
    "            dict(type='BBoxSafeRandomCrop', erosion_rate=0.1, p=1),\n",
    "        ],\n",
    "        p=0.3),\n",
    "]\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=None),\n",
    "    dict(\n",
    "        type='LoadAnnotations',\n",
    "        with_bbox=True,\n",
    "        with_mask=True),\n",
    "        # poly2mask=True),\n",
    "    dict(type='Resize', scale=(900, 720)),\n",
    "    dict(\n",
    "        type='Albu',\n",
    "        transforms=albu_train_transforms,\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_bboxes_labels', 'gt_ignore_flags'],\n",
    "            min_visibility=0.0,\n",
    "            filter_lost_elements=True),\n",
    "        keymap={\n",
    "            'img': 'image',\n",
    "            'gt_masks': 'masks',\n",
    "            'gt_bboxes': 'bboxes'\n",
    "        },\n",
    "        skip_img_without_anno=True),\n",
    "    # dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PackDetInputs', \n",
    "         meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape'))\n",
    "]\n",
    "  \n",
    "cfg.train_pipeline = train_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1097ea-ab9b-4500-8d88-5a9f730bcbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU\n",
    "cfg.optim_wrapper.optimizer.lr = 0.2/8\n",
    "\n",
    "cfg.train_cfg.max_epochs = 25\n",
    "\n",
    "# Changing LR Scheduler\n",
    "cfg.param_scheduler[1].end = cfg.train_cfg.max_epochs\n",
    "cfg.param_scheduler[1].milestones = [10,15]\n",
    "\n",
    "cfg.default_hooks.logger.interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f475865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.vis_backends = [\n",
    "#         dict(type='LocalVisBackend'),\n",
    "#         dict(type='TensorboardVisBackend'),\n",
    "#         dict(type='WandbVisBackend', init_kwargs = dict(project='Binary_RLLPA_Aug', name=''))\n",
    "#     ]\n",
    "# cfg.visualizer.vis_backends = cfg.vis_backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e0785d-a240-4ab0-af9b-cd92c31356ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the runner from config\n",
    "# runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4540d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "@HOOKS.register_module()\n",
    "class FindIoU(Hook):\n",
    "    def __init__(self, name):\n",
    "        os.makedirs(\"bestepochs\", exist_ok=True)\n",
    "        self.bestIoU = 0\n",
    "        self.bestepoch = None\n",
    "        self.name = name\n",
    "        self.metric = BinaryJaccardIndex()\n",
    "        \n",
    "        # RGB format\n",
    "        self.CLS2COLOR = {\n",
    "            1: (228,0,120), # Red\n",
    "            2: (42, 82, 190), # Blue\n",
    "            3: (3, 192, 60) # Green\n",
    "        }\n",
    "        \n",
    "        # define our custom x axis metric\n",
    "        wandb.define_metric(\"coco/epoch\")\n",
    "        # define which metrics will be plotted against it\n",
    "        wandb.define_metric(\n",
    "          \"coco/pGen1IoU\", step_metric=\"coco/epoch\", step_sync=False)\n",
    "        wandb.define_metric(\n",
    "          \"coco/pGen2IoU\", step_metric=\"coco/epoch\", step_sync=False)\n",
    "        wandb.define_metric(\n",
    "          \"coco/meanIoU\", step_metric=\"coco/epoch\", step_sync=False)\n",
    "        \n",
    "        self.artifact = wandb.Artifact(self.name, type='model')\n",
    "        \n",
    "    def after_val(self, runner, **kwargs):\n",
    "        IoUs = []\n",
    "        \n",
    "        checkpoint_file = runner.work_dir + f\"/epoch_{runner.epoch}.pth\"\n",
    "        model = init_detector(runner.cfg, checkpoint_file, device='cuda:0')\n",
    "        meanIoU = []\n",
    "        val_file = runner.cfg.val_dataloader.dataset.ann_file\n",
    "        test_file = runner.cfg.test_dataloader.dataset.ann_file\n",
    "        for f_type, json_path in zip(['pGen1', 'pGen2'], [val_file, test_file]):\n",
    "            \n",
    "            # json_path = f\"{data_type}.json\"\n",
    "            coco = COCO(json_path)\n",
    "            img_dir = f\"combined_data\"\n",
    "            cat_ids = coco.getCatIds()\n",
    "            frames = {}\n",
    "            for idx, img_data in coco.imgs.items():\n",
    "                anns_ids = coco.getAnnIds(imgIds=img_data['id'], catIds=cat_ids, iscrowd=None)\n",
    "                anns = coco.loadAnns(anns_ids)\n",
    "\n",
    "                truth_mask = coco.annToMask(anns[0])\n",
    "                for i in range(1,len(anns)):\n",
    "                    # mask += coco.annToMask(anns[i])\n",
    "                    # mask = np.maximum(mask,coco.annToMask(anns[i])*255) # To have pixel value as 255\n",
    "                    truth_mask = np.maximum(truth_mask,coco.annToMask(anns[i])*1)\n",
    "\n",
    "                img = f'combined_data/{img_data[\"file_name\"]}'  # or img = mmcv.imread(img), which will only load it once\n",
    "                result = inference_detector(model, img)\n",
    "                # outputs = predictor(im)\n",
    "\n",
    "                pred_mask = np.zeros_like(truth_mask)\n",
    "                for i in result.pred_instances.masks.type(torch.int8):\n",
    "                    pred_mask = np.maximum(pred_mask, i.to('cpu').numpy().astype(np.uint8))\n",
    "                    \n",
    "                # frame = label2rgb(pred_mask, cv2.imread(img), alpha=0.3, bg_label=0)*255\n",
    "    \n",
    "                target = torch.tensor(truth_mask)\n",
    "                preds = torch.tensor(pred_mask)\n",
    "            \n",
    "                intersection_mask = np.logical_and(pred_mask == 1, truth_mask == 1)\n",
    "                pred_mask[truth_mask == 1] = 2\n",
    "                pred_mask[intersection_mask] = 3\n",
    "                # Repeating Channels to make it three channels\n",
    "                pred_mask = np.tile(pred_mask[..., np.newaxis], (1,1,3))\n",
    "                \n",
    "                # red -> Wrong Predicted, blue -> Ground Truth, green -> Correct Predicted\n",
    "                frame = io.imread(img)\n",
    "                for color_id in range(1,4):\n",
    "                    mask = np.where(pred_mask == (color_id,)*3, self.CLS2COLOR[color_id], 0).astype('uint8')\n",
    "                    frame = cv2.addWeighted(frame, 1.0, mask, 0.5, 0)\n",
    "                \n",
    "                frames[img_data[\"file_name\"]] = frame\n",
    "\n",
    "                IoUs.append(self.metric(preds, target).item())\n",
    "                \n",
    "            \n",
    "            size1,size2,_ = frame.shape\n",
    "            out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 1, (size2, size1), True)\n",
    "            # Sorting the frames according to frame number eg: p3_frame_000530..PNG\n",
    "            for _,i in sorted(frames.items(), key=lambda x: x[0]):\n",
    "                out_img = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "                out.write(out_img)\n",
    "            out.release()\n",
    "            \n",
    "            # Convert MPV4 codec to libx264 codec\n",
    "            input_file = 'output.mp4'\n",
    "            output_file = f_type+'.mp4'\n",
    "            clip = VideoFileClip(input_file)\n",
    "            clip.write_videofile(output_file, codec='libx264')\n",
    "\n",
    "            # Collect all meanIoUs for all Generalization Patients\n",
    "            meanIoU.append(sum(IoUs)/len(IoUs))\n",
    "            print(f\"IoU: {sum(IoUs)/len(IoUs)}\")\n",
    "            \n",
    "            # axes are (time, channel, height, width)\n",
    "            wandb.log({f\"{self.name}_{f_type}_epoch_{runner.epoch}\": wandb.Video(output_file)})\n",
    "            \n",
    "        for IoU, log in zip(meanIoU, ['pGen1', 'pGen2']):\n",
    "            wandb.log({f'coco/{log}':IoU, 'coco/epoch':runner.epoch})\n",
    "            \n",
    "        meanIoU = sum(meanIoU)/len(meanIoU)\n",
    "        if meanIoU > self.bestIoU:\n",
    "            self.bestIoU = meanIoU\n",
    "            self.bestepoch = checkpoint_file\n",
    "\n",
    "        print(f\"meanIoU: {meanIoU}\")\n",
    "        wandb.log({'coco/iou':meanIoU, 'coco/epoch':runner.epoch})\n",
    "        \n",
    "        print(f\"Saving checkpoint of epoch {runner.epoch} to wandb\")\n",
    "        self.artifact.add_file(checkpoint_file, name=f'epoch_{runner.epoch}.pth')\n",
    "        # wandb.log_artifact(self.artifact)\n",
    "    def after_run(self,runner, **kwargs):\n",
    "        shutil.copy(self.bestepoch, f\"bestepochs/{self.name}.pth\")\n",
    "        print(f\"Saving best checkpoint to wandb\")\n",
    "        self.artifact.add_file(self.bestepoch, name=f\"best.pth\")\n",
    "        wandb.log_artifact(self.artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f7bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/25 16:37:57 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 517293159\n",
      "    GPU 0: NVIDIA A10\n",
      "    CUDA_HOME: /usr\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.13.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.14.1+cu117\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.7.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: None\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/25 16:37:57 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Config:\n",
      "default_scope = 'mmdet'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=100),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "    dict(type='TensorboardVisBackend'),\n",
      "    dict(\n",
      "        type='WandbVisBackend',\n",
      "        init_kwargs=dict(project='RLL_Aug', name='AllPatients-p1p2'))\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(\n",
      "            type='WandbVisBackend',\n",
      "            init_kwargs=dict(project='RLL_Aug', name='AllPatients-p1p2'))\n",
      "    ],\n",
      "    name='visualizer')\n",
      "log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n",
      "log_level = 'INFO'\n",
      "load_from = './pre_trained_checkpoints/mask_rcnn_r50_fpn_mstrain-poly_3x_coco_20210524_201154-21b550bb.pth'\n",
      "resume = False\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = '.'\n",
      "backend_args = None\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(type='RandomChoiceResize', scales=[(1200, 1000), (900, 720)]),\n",
      "    dict(\n",
      "        type='Albu',\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='ShiftScaleRotate',\n",
      "                shift_limit=0.1,\n",
      "                scale_limit=0.2,\n",
      "                rotate_limit=30,\n",
      "                interpolation=1,\n",
      "                p=0.3),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='RGBShift',\n",
      "                        r_shift_limit=10,\n",
      "                        g_shift_limit=10,\n",
      "                        b_shift_limit=10,\n",
      "                        p=1.0),\n",
      "                    dict(\n",
      "                        type='HueSaturationValue',\n",
      "                        hue_shift_limit=20,\n",
      "                        sat_shift_limit=30,\n",
      "                        val_shift_limit=20,\n",
      "                        p=1.0),\n",
      "                    dict(\n",
      "                        type='ColorJitter',\n",
      "                        brightness=0.4,\n",
      "                        contrast=0.4,\n",
      "                        saturation=0.4,\n",
      "                        hue=0.2,\n",
      "                        p=1.0),\n",
      "                    dict(type='RandomBrightness', limit=0.5, p=1.0),\n",
      "                    dict(\n",
      "                        type='RandomBrightnessContrast',\n",
      "                        brightness_limit=0.3,\n",
      "                        contrast_limit=0.3,\n",
      "                        p=1.0)\n",
      "                ],\n",
      "                p=0.4),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='CropNonEmptyMaskIfExists',\n",
      "                        height=720,\n",
      "                        width=720,\n",
      "                        p=1),\n",
      "                    dict(type='BBoxSafeRandomCrop', erosion_rate=0.1, p=1)\n",
      "                ],\n",
      "                p=0.6),\n",
      "            dict(\n",
      "                type='JpegCompression',\n",
      "                quality_lower=65,\n",
      "                quality_upper=95,\n",
      "                p=0.2),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(type='Blur', blur_limit=3, p=1.0),\n",
      "                    dict(type='MedianBlur', blur_limit=5, p=1.0)\n",
      "                ],\n",
      "                p=0.2),\n",
      "            dict(\n",
      "                type='OneOf',\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='ElasticTransform',\n",
      "                        p=1,\n",
      "                        alpha=120,\n",
      "                        sigma=6.0,\n",
      "                        alpha_affine=3.5999999999999996),\n",
      "                    dict(type='GridDistortion', p=1),\n",
      "                    dict(\n",
      "                        type='OpticalDistortion',\n",
      "                        distort_limit=2,\n",
      "                        shift_limit=0.5,\n",
      "                        p=1)\n",
      "                ],\n",
      "                p=0.2)\n",
      "        ],\n",
      "        bbox_params=dict(\n",
      "            type='BboxParams',\n",
      "            format='pascal_voc',\n",
      "            label_fields=['gt_bboxes_labels', 'gt_ignore_flags'],\n",
      "            min_visibility=0.0,\n",
      "            filter_lost_elements=True),\n",
      "        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n",
      "        skip_img_without_anno=True),\n",
      "    dict(\n",
      "        type='PackDetInputs',\n",
      "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape'))\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
      "    dict(\n",
      "        type='LoadAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_mask=True,\n",
      "        poly2mask=False),\n",
      "    dict(\n",
      "        type='PackDetInputs',\n",
      "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
      "                   'scale_factor'))\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=12,\n",
      "    num_workers=24,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    dataset=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=2,\n",
      "        dataset=dict(\n",
      "            type='CocoDataset',\n",
      "            data_root='.',\n",
      "            ann_file='./JSONS/AllPatients-p1p2.json',\n",
      "            data_prefix=dict(img='combined_data/'),\n",
      "            filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile', backend_args=None),\n",
      "                dict(\n",
      "                    type='LoadAnnotations',\n",
      "                    with_bbox=True,\n",
      "                    with_mask=True,\n",
      "                    poly2mask=False),\n",
      "                dict(\n",
      "                    type='RandomResize',\n",
      "                    scale=[(1333, 640), (1333, 800)],\n",
      "                    keep_ratio=True),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(type='PackDetInputs')\n",
      "            ],\n",
      "            backend_args=None,\n",
      "            metainfo=dict(classes=('Artery', ), palette=[(220, 20, 60)]))))\n",
      "val_dataloader = dict(\n",
      "    batch_size=12,\n",
      "    num_workers=24,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='.',\n",
      "        ann_file='./JSONS/p1.json',\n",
      "        data_prefix=dict(img='combined_data/'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                poly2mask=False),\n",
      "            dict(\n",
      "                type='PackDetInputs',\n",
      "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
      "                           'scale_factor'))\n",
      "        ],\n",
      "        backend_args=None,\n",
      "        metainfo=dict(classes=('Artery', ), palette=[(220, 20, 60)])))\n",
      "test_dataloader = dict(\n",
      "    batch_size=12,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    drop_last=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='CocoDataset',\n",
      "        data_root='.',\n",
      "        ann_file='./JSONS/p2.json',\n",
      "        data_prefix=dict(img='combined_data/'),\n",
      "        test_mode=True,\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', backend_args=None),\n",
      "            dict(type='Resize', scale=(1333, 800), keep_ratio=True),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=True,\n",
      "                poly2mask=False),\n",
      "            dict(\n",
      "                type='PackDetInputs',\n",
      "                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
      "                           'scale_factor'))\n",
      "        ],\n",
      "        backend_args=None,\n",
      "        metainfo=dict(classes=('Artery', ), palette=[(220, 20, 60)])))\n",
      "val_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file='./JSONS/p1.json',\n",
      "    metric=['bbox', 'segm'],\n",
      "    backend_args=None)\n",
      "test_evaluator = dict(\n",
      "    type='CocoMetric',\n",
      "    ann_file='./JSONS/p2.json',\n",
      "    metric=['bbox', 'segm'],\n",
      "    backend_args=None)\n",
      "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=25, val_interval=1)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
      "    dict(\n",
      "        type='MultiStepLR',\n",
      "        begin=0,\n",
      "        end=25,\n",
      "        by_epoch=True,\n",
      "        milestones=[10, 15],\n",
      "        gamma=0.1)\n",
      "]\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(type='SGD', lr=0.025, momentum=0.9, weight_decay=0.0001))\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "model = dict(\n",
      "    type='MaskRCNN',\n",
      "    data_preprocessor=dict(\n",
      "        type='DetDataPreprocessor',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        bgr_to_rgb=True,\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32),\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=1,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=1,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            mask_size=28,\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "metainfo = dict(classes=('Artery', ), palette=[(220, 20, 60)])\n",
      "custom_hooks = [dict(type='FindIoU', name='AllPatients-p1p2')]\n",
      "work_dir = './RLL_NoAug/AllPatients-p1p2'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskhader\u001b[0m (\u001b[33mplakhsa-mgh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/RLL_NoAug/AllPatients-p1p2/20230525_163757/vis_data/wandb/run-20230525_163759-9qufc3fg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/plakhsa-mgh/RLL_Aug/runs/9qufc3fg' target=\"_blank\">AllPatients-p1p2</a></strong> to <a href='https://wandb.ai/plakhsa-mgh/RLL_Aug' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/plakhsa-mgh/RLL_Aug' target=\"_blank\">https://wandb.ai/plakhsa-mgh/RLL_Aug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/plakhsa-mgh/RLL_Aug/runs/9qufc3fg' target=\"_blank\">https://wandb.ai/plakhsa-mgh/RLL_Aug/runs/9qufc3fg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/25 16:38:04 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/25 16:38:04 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(NORMAL      ) FindIoU                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(NORMAL      ) FindIoU                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "05/25 16:38:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: torchvision://resnet50\n",
      "05/25 16:38:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
      "05/25 16:38:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "Loads checkpoint by local backend from path: ./pre_trained_checkpoints/mask_rcnn_r50_fpn_mstrain-poly_3x_coco_20210524_201154-21b550bb.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "05/25 16:38:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Load checkpoint from ./pre_trained_checkpoints/mask_rcnn_r50_fpn_mstrain-poly_3x_coco_20210524_201154-21b550bb.pth\n",
      "05/25 16:38:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "05/25 16:38:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "05/25 16:38:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to /home/ubuntu/RLL_NoAug/AllPatients-p1p2.\n",
      "05/25 16:39:47 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [1][100/465]  lr: 4.9800e-03  eta: 3:16:20  time: 1.0366  data_time: 0.0137  memory: 15041  loss: 1.1940  loss_rpn_cls: 0.0774  loss_rpn_bbox: 0.0317  loss_cls: 0.2692  acc: 90.2832  loss_bbox: 0.3792  loss_mask: 0.4365\n",
      "05/25 16:41:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [1][200/465]  lr: 9.9850e-03  eta: 3:19:05  time: 1.0759  data_time: 0.0147  memory: 16135  loss: 0.8635  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0234  loss_cls: 0.2056  acc: 91.6829  loss_bbox: 0.3119  loss_mask: 0.2905\n",
      "05/25 16:43:23 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [1][300/465]  lr: 1.4990e-02  eta: 3:20:06  time: 1.1002  data_time: 0.0129  memory: 16430  loss: 0.7580  loss_rpn_cls: 0.0176  loss_rpn_bbox: 0.0208  loss_cls: 0.1659  acc: 95.1660  loss_bbox: 0.2994  loss_mask: 0.2544\n",
      "05/25 16:45:13 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [1][400/465]  lr: 1.9995e-02  eta: 3:19:54  time: 1.0972  data_time: 0.0127  memory: 16648  loss: 0.7106  loss_rpn_cls: 0.0177  loss_rpn_bbox: 0.0203  loss_cls: 0.1505  acc: 94.0592  loss_bbox: 0.2853  loss_mask: 0.2369\n",
      "05/25 16:46:23 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: mask-rcnn_r50_fpn_ms-poly-3x_coco_20230525_163757\n",
      "05/25 16:46:23 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "05/25 16:47:40 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.55s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.417\n",
      "05/25 16:47:43 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - bbox_mAP_copypaste: 0.095 0.274 0.024 0.007 0.108 0.119\n",
      "05/25 16:47:43 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=2.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.56s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.541\n",
      "05/25 16:47:47 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - segm_mAP_copypaste: 0.139 0.292 0.136 0.002 0.130 0.251\n",
      "05/25 16:47:47 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(val) [1][83/83]    coco/bbox_mAP: 0.0950  coco/bbox_mAP_50: 0.2740  coco/bbox_mAP_75: 0.0240  coco/bbox_mAP_s: 0.0070  coco/bbox_mAP_m: 0.1080  coco/bbox_mAP_l: 0.1190  coco/segm_mAP: 0.1390  coco/segm_mAP_50: 0.2920  coco/segm_mAP_75: 0.1360  coco/segm_mAP_s: 0.0020  coco/segm_mAP_m: 0.1300  coco/segm_mAP_l: 0.2510  data_time: 0.0216  time: 0.8984\n",
      "Loads checkpoint by local backend from path: /home/ubuntu/RLL_NoAug/AllPatients-p1p2/epoch_1.pth\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Moviepy - Building video pGen1.mp4.\n",
      "Moviepy - Writing video pGen1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready pGen1.mp4\n",
      "IoU: 0.21404794042203332\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Moviepy - Building video pGen2.mp4.\n",
      "Moviepy - Writing video pGen2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready pGen2.mp4\n",
      "IoU: 0.3362414434629087\n",
      "meanIoU: 0.275144691942471\n",
      "Saving checkpoint of epoch 1 to wandb\n",
      "05/25 16:52:51 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [2][100/465]  lr: 2.5000e-02  eta: 3:18:17  time: 1.0982  data_time: 0.0210  memory: 16560  loss: 0.6488  loss_rpn_cls: 0.0116  loss_rpn_bbox: 0.0185  loss_cls: 0.1342  acc: 95.2799  loss_bbox: 0.2676  loss_mask: 0.2169\n",
      "05/25 16:54:41 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [2][200/465]  lr: 2.5000e-02  eta: 3:17:15  time: 1.0976  data_time: 0.0127  memory: 16547  loss: 0.6410  loss_rpn_cls: 0.0092  loss_rpn_bbox: 0.0182  loss_cls: 0.1268  acc: 96.0286  loss_bbox: 0.2711  loss_mask: 0.2157\n",
      "05/25 16:56:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [2][300/465]  lr: 2.5000e-02  eta: 3:15:47  time: 1.0946  data_time: 0.0125  memory: 16639  loss: 0.5894  loss_rpn_cls: 0.0089  loss_rpn_bbox: 0.0165  loss_cls: 0.1156  acc: 94.9544  loss_bbox: 0.2465  loss_mask: 0.2018\n",
      "05/25 16:58:21 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train)  [2][400/465]  lr: 2.5000e-02  eta: 3:14:24  time: 1.1032  data_time: 0.0129  memory: 16772  loss: 0.6002  loss_rpn_cls: 0.0075  loss_rpn_bbox: 0.0168  loss_cls: 0.1190  acc: 95.2148  loss_bbox: 0.2569  loss_mask: 0.2001\n",
      "05/25 16:59:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: mask-rcnn_r50_fpn_ms-poly-3x_coco_20230525_163757\n",
      "05/25 16:59:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "05/25 17:00:51 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=2.43s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.60s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.447\n",
      "05/25 17:00:55 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - bbox_mAP_copypaste: 0.207 0.450 0.159 0.010 0.230 0.234\n",
      "05/25 17:00:55 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=2.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.62s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.465\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.609\n",
      "05/25 17:00:59 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - segm_mAP_copypaste: 0.246 0.465 0.225 0.004 0.247 0.348\n",
      "05/25 17:00:59 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(val) [2][83/83]    coco/bbox_mAP: 0.2070  coco/bbox_mAP_50: 0.4500  coco/bbox_mAP_75: 0.1590  coco/bbox_mAP_s: 0.0100  coco/bbox_mAP_m: 0.2300  coco/bbox_mAP_l: 0.2340  coco/segm_mAP: 0.2460  coco/segm_mAP_50: 0.4650  coco/segm_mAP_75: 0.2250  coco/segm_mAP_s: 0.0040  coco/segm_mAP_m: 0.2470  coco/segm_mAP_l: 0.3480  data_time: 0.0165  time: 0.9357\n",
      "Loads checkpoint by local backend from path: /home/ubuntu/RLL_NoAug/AllPatients-p1p2/epoch_2.pth\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Moviepy - Building video pGen1.mp4.\n",
      "Moviepy - Writing video pGen1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready pGen1.mp4\n",
      "IoU: 0.17772409696199504\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Moviepy - Building video pGen2.mp4.\n",
      "Moviepy - Writing video pGen2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready pGen2.mp4\n",
      "IoU: 0.2696863304348013\n",
      "meanIoU: 0.22370521369839816\n",
      "Saving checkpoint of epoch 2 to wandb\n"
     ]
    }
   ],
   "source": [
    "for file_name in os.listdir(\"./JSONS\"):\n",
    "    # If file doesn't contain \"AllPatients\" continue\n",
    "    if \"All\" not in file_name:\n",
    "        continue\n",
    "    train_file = file_name\n",
    "    pGen_names = file_name.split('-')[1]\n",
    "    first_p = pGen_names.find('p')\n",
    "    second_p = pGen_names.rfind('p')\n",
    "    val_file = pGen_names[first_p:second_p]+\".json\"\n",
    "    test_file = pGen_names[second_p:]\n",
    "    \n",
    "    # train_file = val_file = test_file = 'p10.json'\n",
    "    \n",
    "    if val_file in ['p1.json', 'p3.json', 'p5.json']:\n",
    "        continue\n",
    "\n",
    "    name = file_name.split('.')[0]\n",
    "    \n",
    "    cfg.custom_hooks = [\n",
    "        dict(type='FindIoU', name=name)\n",
    "    ]\n",
    "    \n",
    "    cfg.vis_backends = [\n",
    "        dict(type='LocalVisBackend'),\n",
    "        dict(type='TensorboardVisBackend'),\n",
    "        dict(type='WandbVisBackend', init_kwargs = dict(project='Binary_RLLPA_Aug', name=name))\n",
    "    ]\n",
    "    cfg.visualizer.vis_backends = cfg.vis_backends\n",
    "\n",
    "    cfg.data_root = '.'\n",
    "\n",
    "    cfg.train_dataloader.batch_size = 12\n",
    "    cfg.train_dataloader.num_workers = 24\n",
    "    cfg.train_dataloader.dataset.dataset.ann_file = f'./JSONS/{train_file}'\n",
    "    cfg.train_dataloader.dataset.dataset.data_root = cfg.data_root\n",
    "    cfg.train_dataloader.dataset.dataset.data_prefix.img = 'combined_data/'\n",
    "    cfg.train_dataloader.dataset.dataset.metainfo = cfg.metainfo\n",
    "    \n",
    "    cfg.train_dataloader.dataset.dataset.pipeline = cfg.train_pipeline\n",
    "    \n",
    "    cfg.train_dataloader.dataset.times = 2\n",
    "\n",
    "    cfg.val_dataloader.batch_size = 12\n",
    "    cfg.val_dataloader.num_workers = 24\n",
    "    cfg.val_dataloader.dataset.ann_file = f'./JSONS/{val_file}'\n",
    "    cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "    cfg.val_dataloader.dataset.data_prefix.img = 'combined_data/'\n",
    "    cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "    cfg.test_dataloader.batch_size = 12\n",
    "    cfg.test_dataloader.dataset.ann_file = f'./JSONS/{test_file}'\n",
    "    cfg.test_dataloader.dataset.data_root = cfg.data_root\n",
    "    cfg.test_dataloader.dataset.data_prefix.img = 'combined_data/'\n",
    "    cfg.test_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "    # Modify metric config\n",
    "    cfg.val_evaluator.ann_file = cfg.data_root+'/'+f'JSONS/{val_file}'\n",
    "    cfg.test_evaluator.ann_file = cfg.data_root+'/'+f'JSONS/{test_file}'\n",
    "\n",
    "    # Modify num classes of the model in box head and mask head\n",
    "    cfg.model.roi_head.bbox_head.num_classes = 1\n",
    "    cfg.model.roi_head.mask_head.num_classes = 1\n",
    "\n",
    "    # We can still the pre-trained Mask RCNN model to obtain a higher performance\n",
    "    cfg.load_from = './pre_trained_checkpoints/mask_rcnn_r50_fpn_mstrain-poly_3x_coco_20210524_201154-21b550bb.pth'\n",
    "\n",
    "    # Set up working dir to save files and logs.\n",
    "    cfg.work_dir = f\"./Binary_RLLPA_Aug/{name}\"\n",
    "    \n",
    "    try:\n",
    "        runner = Runner.from_cfg(cfg)\n",
    "    except wandb.Error:\n",
    "        wandb.init(dir=cfg.work_dir, project='Binary_RLLPA_Aug', name=name)\n",
    "        runner = Runner.from_cfg(cfg)\n",
    "\n",
    "    runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969c87d-e1ab-4734-ae94-f56701ec25db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # load tensorboard in colab\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# # see curves in tensorboard\n",
    "# %tensorboard --logdir ./Binary_RLLPA_Aug --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c83779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the logs and everything without the weights\n",
    "!zip -r -qq Binary_RLLPA_Aug.zip Binary_RLLPA_Aug -x \\*.pth \\*last_checkpoint \\*.mp4\n",
    "!zip -r -qq bestepochs_Binary_RLLPA_Aug.zip bestepochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a18c8-51b3-4001-a1ba-e70ccecf9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp bestepochs_Binary_RLLPA_Aug.zip s3://all-patients/\n",
    "!aws s3 cp Binary_RLLPA_Aug.zip s3://all-patients/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08966559-f476-4855-8665-aa5a084e7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE and Moved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
